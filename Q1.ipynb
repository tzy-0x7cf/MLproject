{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegressionCustom:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights and bias\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.num_iterations):\n",
    "            # Linear combination of features and weights\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # Apply sigmoid activation\n",
    "            predictions = self.sigmoid(linear_model)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / num_samples) * np.sum(predictions - y)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Linear combination of features and weights\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "        # Apply sigmoid activation\n",
    "        predictions = self.sigmoid(linear_model)\n",
    "\n",
    "        # Convert probabilities to binary predictions (0 or 1)\n",
    "        binary_predictions = np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "        return binary_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNearestNeighborCustom:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for x_test in X_test:\n",
    "            distances = np.linalg.norm(self.X_train - x_test, axis=1)\n",
    "            nearest_neighbors_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = self.y_train[nearest_neighbors_indices]\n",
    "            predicted_label = np.bincount(nearest_labels).argmax()\n",
    "            predictions.append(predicted_label)\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeCustom:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def predict(self, X, sample_weights=None):\n",
    "        return np.array([self.traverse_tree(x, self.tree, sample_weights) for x in X])\n",
    "\n",
    "    def traverse_tree(self, x, node, sample_weights=None):\n",
    "        if 'class' in node:\n",
    "            return node['class']\n",
    "\n",
    "        feature_value = x[node['feature_index']]\n",
    "        threshold = node['threshold']\n",
    "\n",
    "        if feature_value < threshold:\n",
    "            return self.traverse_tree(x, node['left'], sample_weights)\n",
    "        else:\n",
    "            return self.traverse_tree(x, node['right'], sample_weights)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        self.tree = self.build_tree(X, y, depth=self.max_depth, sample_weights=sample_weights)\n",
    "\n",
    "    def build_tree(self, X, y, depth, sample_weights=None):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        if sample_weights is not None:\n",
    "            sample_weights = np.ones(num_samples) / num_samples\n",
    "\n",
    "        # If all samples have the same class or maximum depth is reached, create a leaf node\n",
    "        if len(unique_classes) == 1 or depth == 0:\n",
    "            return {'class': unique_classes[0]}\n",
    "\n",
    "        # Choose the best split based on a criterion (e.g., Gini impurity, entropy)\n",
    "        best_split = self.find_best_split(X, y, sample_weights)\n",
    "\n",
    "        if best_split is None:\n",
    "            # Unable to find a split, create a leaf node\n",
    "            return {'class': np.bincount(y, weights=sample_weights).argmax()}\n",
    "\n",
    "        best_feature_index, best_threshold = best_split\n",
    "\n",
    "        # Split the data\n",
    "        mask = X[:, best_feature_index] < best_threshold\n",
    "        X_left, y_left = X[mask], y[mask]\n",
    "        X_right, y_right = X[~mask], y[~mask]\n",
    "\n",
    "        # Recursively build the left and right subtree\n",
    "        left_subtree = self.build_tree(X_left, y_left, depth - 1, sample_weights)\n",
    "        right_subtree = self.build_tree(X_right, y_right, depth - 1, sample_weights)\n",
    "\n",
    "        return {\n",
    "            'feature_index': best_feature_index,\n",
    "            'threshold': best_threshold,\n",
    "            'left': left_subtree,\n",
    "            'right': right_subtree\n",
    "        }\n",
    "\n",
    "    def find_best_split(self, X, y, sample_weights=None):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        # Initialize variables to keep track of the best split\n",
    "        best_gini = float('inf')\n",
    "        best_split = None\n",
    "\n",
    "        for feature_index in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                mask = X[:, feature_index] < threshold\n",
    "                y_left, y_right = y[mask], y[~mask]\n",
    "                \n",
    "                # if sample_weights is not None:\n",
    "                #     if len(sample_weights) != len(mask):\n",
    "                #         print(len(X))\n",
    "                #         print(len(sample_weights))\n",
    "                #         print(len(mask))\n",
    "\n",
    "                if sample_weights is not None:\n",
    "                    weight_left, weight_right = sample_weights[mask], sample_weights[~mask]\n",
    "                    gini = self.calculate_weighted_gini(y_left, y_right, weight_left, weight_right)\n",
    "                else:\n",
    "                    gini = self.calculate_gini(y_left, y_right)\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_split = (feature_index, threshold)\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def calculate_gini(self, y_left, y_right):\n",
    "        size_left, size_right = len(y_left), len(y_right)\n",
    "        size_total = size_left + size_right\n",
    "\n",
    "        gini_left = 1.0 - sum((np.sum(y_left == c) / size_left) ** 2 for c in np.unique(y_left))\n",
    "        gini_right = 1.0 - sum((np.sum(y_right == c) / size_right) ** 2 for c in np.unique(y_right))\n",
    "\n",
    "        gini = (size_left / size_total) * gini_left + (size_right / size_total) * gini_right\n",
    "        return gini\n",
    "\n",
    "    def calculate_weighted_gini(self, y_left, y_right, weight_left, weight_right):\n",
    "        size_left, size_right = len(y_left), len(y_right)\n",
    "        size_total = size_left + size_right\n",
    "\n",
    "        gini_left = 1.0 - sum((np.sum(y_left == c) / size_left) ** 2 * w for c, w in zip(np.unique(y_left), weight_left))\n",
    "        gini_right = 1.0 - sum((np.sum(y_right == c) / size_right) ** 2 * w for c, w in zip(np.unique(y_right), weight_right))\n",
    "\n",
    "        gini = (size_left / size_total) * gini_left + (size_right / size_total) * gini_right\n",
    "        return gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "class SVMCustom:\n",
    "    def __init__(self, kernel='linear', C=1.0):\n",
    "        self.model = SVC(kernel=kernel, C=C)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RandomForestCustom:\n",
    "    def __init__(self, n_estimators=10, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y, sample_weights = None):\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeCustom(max_depth=self.max_depth)\n",
    "            # Randomly sample a subset of data for each tree (bootstrapping)\n",
    "            indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            tree.fit(X[indices], y[indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions using each tree and take a majority vote\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BoostingCustom:\n",
    "    def __init__(self, n_estimators=10, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples = len(X)\n",
    "        \n",
    "        sample_weights = np.ones(num_samples) / num_samples  # Initialize weights uniformly\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            weak_model = DecisionTreeCustom(max_depth=self.max_depth)\n",
    "            weak_model.fit(X, y, sample_weights)\n",
    "\n",
    "            y_pred = weak_model.predict(X)\n",
    "\n",
    "            # Calculate weighted error\n",
    "            error = np.sum(sample_weights * (y_pred != y)) / np.sum(sample_weights)\n",
    "\n",
    "            # Calculate model weight (alpha)\n",
    "            alpha = 0.5 * np.log((1 - error) / error)\n",
    "\n",
    "            # Update sample weights\n",
    "            sample_weights *= np.exp(-alpha * y * y_pred)\n",
    "            sample_weights /= np.sum(sample_weights)  # Normalize weights\n",
    "\n",
    "            self.models.append(weak_model)\n",
    "            self.alphas.append(alpha)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Combine predictions based on weighted majority vote\n",
    "        predictions = np.zeros(len(X))\n",
    "        for model, alpha in zip(self.models, self.alphas):\n",
    "            predictions += alpha * model.predict(X)\n",
    "\n",
    "        return np.sign(predictions).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 8)\n",
      "(93, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load project_dataset1\n",
    "file_path1 = 'project3_dataset1.txt'\n",
    "data1 = pd.read_csv(file_path1, delimiter='\\t', header=None)\n",
    "X1 = data1.iloc[:, :-1].values\n",
    "y1 = data1.iloc[:, -1].values\n",
    "\n",
    "# Load project_dataset2\n",
    "file_path2 = 'project3_dataset2.txt'\n",
    "data2 = pd.read_csv(file_path2, delimiter='\\t', header=None)\n",
    "X2 = data2.iloc[:, 1:-1].values  \n",
    "y2 = data2.iloc[:, -1].values\n",
    "\n",
    "# Preprocess project_dataset1\n",
    "scaler1 = StandardScaler()\n",
    "X1_scaled = scaler1.fit_transform(X1)\n",
    "\n",
    "# Preprocess project_dataset2\n",
    "le = LabelEncoder()\n",
    "X2[:, 3] = le.fit_transform(X2[:, 3])  # Encode nominal feature to numerical\n",
    "X2 = X2.astype(float)  # Convert the entire array to float\n",
    "scaler2 = StandardScaler()\n",
    "X2_scaled = scaler2.fit_transform(X2)\n",
    "\n",
    "# Split datasets into training and testing sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1_scaled, y1, test_size=0.2, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_scaled, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X2_train.shape)\n",
    "print(X2_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression on project_dataset1:\n",
      "  Average Accuracy on project_dataset1: 0.9737\n",
      "  Average Precision on project_dataset1: 0.9809\n",
      "  Average Recall on project_dataset1: 0.9483\n",
      "  Average F1 on project_dataset1: 0.9639\n",
      "  Average AUC on project_dataset1: 0.9685\n",
      "\n",
      "Evaluating KNN on project_dataset1:\n",
      "  Average Accuracy on project_dataset1: 0.9667\n",
      "  Average Precision on project_dataset1: 0.9827\n",
      "  Average Recall on project_dataset1: 0.9297\n",
      "  Average F1 on project_dataset1: 0.9535\n",
      "  Average AUC on project_dataset1: 0.9592\n",
      "\n",
      "Evaluating Decision Tree on project_dataset1:\n",
      "  Average Accuracy on project_dataset1: 0.7964\n",
      "  Average Precision on project_dataset1: 0.6443\n",
      "  Average Recall on project_dataset1: 0.4853\n",
      "  Average F1 on project_dataset1: 0.5356\n",
      "  Average AUC on project_dataset1: 0.7343\n",
      "\n",
      "Evaluating SVM on project_dataset1:\n",
      "  Average Accuracy on project_dataset1: 0.9737\n",
      "  Average Precision on project_dataset1: 0.9732\n",
      "  Average Recall on project_dataset1: 0.9576\n",
      "  Average F1 on project_dataset1: 0.9640\n",
      "  Average AUC on project_dataset1: 0.9705\n",
      "\n",
      "Evaluating Random Forest on project_dataset1:\n",
      "  Average Accuracy on project_dataset1: 0.7012\n",
      "  Average Precision on project_dataset1: 0.9000\n",
      "  Average Recall on project_dataset1: 0.1968\n",
      "  Average F1 on project_dataset1: 0.2781\n",
      "  Average AUC on project_dataset1: 0.5984\n",
      "\n",
      "Evaluating Boosting on project_dataset1:\n",
      "  Average Accuracy on project_dataset1: 0.8702\n",
      "  Average Precision on project_dataset1: 0.9418\n",
      "  Average Recall on project_dataset1: 0.6851\n",
      "  Average F1 on project_dataset1: 0.7090\n",
      "  Average AUC on project_dataset1: 0.8342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "\n",
    "# Define custom models\n",
    "logistic_regression_custom = LogisticRegressionCustom()\n",
    "knn_custom = KNearestNeighborCustom(k=3)\n",
    "decision_tree_custom = DecisionTreeCustom(max_depth=3)\n",
    "svm_custom = SVMCustom()\n",
    "random_forest_custom = RandomForestCustom(max_depth=3)\n",
    "boosting_custom = BoostingCustom(max_depth=3)\n",
    "\n",
    "# Create a dictionary of models\n",
    "models = {\n",
    "    'Logistic Regression': logistic_regression_custom,\n",
    "    'KNN': knn_custom,\n",
    "    'Decision Tree': decision_tree_custom,\n",
    "    'SVM': svm_custom,\n",
    "    'Random Forest': random_forest_custom,\n",
    "    'Boosting': boosting_custom\n",
    "}\n",
    "\n",
    "# Define evaluation metrics\n",
    "metrics = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': precision_score,\n",
    "    'Recall': recall_score,\n",
    "    'F1': f1_score,\n",
    "    'AUC': roc_auc_score\n",
    "}\n",
    "\n",
    "# Iterate through each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} on project_dataset1:\")\n",
    "    \n",
    "    # Initialize lists to store metric scores for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "\n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for train_index, test_index in skf.split(X1_scaled, y1):\n",
    "        X_train, X_test = X1_scaled[train_index], X1_scaled[test_index]\n",
    "        y_train, y_test = y1[train_index], y1[test_index] \n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate metrics\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "    # Display average scores over all folds for project_dataset1\n",
    "    print(f\"  Average Accuracy on project_dataset1: {np.mean(accuracy_scores):.4f}\")\n",
    "    print(f\"  Average Precision on project_dataset1: {np.mean(precision_scores):.4f}\")\n",
    "    print(f\"  Average Recall on project_dataset1: {np.mean(recall_scores):.4f}\")\n",
    "    print(f\"  Average F1 on project_dataset1: {np.mean(f1_scores):.4f}\")\n",
    "    print(f\"  Average AUC on project_dataset1: {np.mean(auc_scores):.4f}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression on project_dataset2:\n",
      "  Average Accuracy on project_dataset2: 0.7358\n",
      "  Average Precision on project_dataset2: 0.6526\n",
      "  Average Recall on project_dataset2: 0.5500\n",
      "  Average F1 on project_dataset2: 0.5830\n",
      "  Average AUC on project_dataset2: 0.6923\n",
      "\n",
      "Evaluating KNN on project_dataset2:\n",
      "  Average Accuracy on project_dataset2: 0.6667\n",
      "  Average Precision on project_dataset2: 0.5238\n",
      "  Average Recall on project_dataset2: 0.4625\n",
      "  Average F1 on project_dataset2: 0.4875\n",
      "  Average AUC on project_dataset2: 0.6189\n",
      "\n",
      "Evaluating Decision Tree on project_dataset2:\n",
      "  Average Accuracy on project_dataset2: 0.6580\n",
      "  Average Precision on project_dataset2: 0.2167\n",
      "  Average Recall on project_dataset2: 0.0250\n",
      "  Average F1 on project_dataset2: 0.0439\n",
      "  Average AUC on project_dataset2: 0.5092\n",
      "\n",
      "Evaluating SVM on project_dataset2:\n",
      "  Average Accuracy on project_dataset2: 0.7164\n",
      "  Average Precision on project_dataset2: 0.6134\n",
      "  Average Recall on project_dataset2: 0.5125\n",
      "  Average F1 on project_dataset2: 0.5504\n",
      "  Average AUC on project_dataset2: 0.6686\n",
      "\n",
      "Evaluating Random Forest on project_dataset2:\n",
      "  Average Accuracy on project_dataset2: 0.6537\n",
      "  Average Precision on project_dataset2: 0.0000\n",
      "  Average Recall on project_dataset2: 0.0000\n",
      "  Average F1 on project_dataset2: 0.0000\n",
      "  Average AUC on project_dataset2: 0.5000\n",
      "\n",
      "Evaluating Boosting on project_dataset2:\n",
      "  Average Accuracy on project_dataset2: 0.6776\n",
      "  Average Precision on project_dataset2: 0.5167\n",
      "  Average Recall on project_dataset2: 0.0813\n",
      "  Average F1 on project_dataset2: 0.1387\n",
      "  Average AUC on project_dataset2: 0.5373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define custom models\n",
    "logistic_regression_custom = LogisticRegressionCustom()\n",
    "knn_custom = KNearestNeighborCustom(k=3)\n",
    "decision_tree_custom = DecisionTreeCustom(max_depth=3)\n",
    "svm_custom = SVMCustom()\n",
    "random_forest_custom = RandomForestCustom(max_depth=3)\n",
    "boosting_custom = BoostingCustom(max_depth=3)\n",
    "\n",
    "# Create a dictionary of models\n",
    "models = {\n",
    "    'Logistic Regression': logistic_regression_custom,\n",
    "    'KNN': knn_custom,\n",
    "    'Decision Tree': decision_tree_custom,\n",
    "    'SVM': svm_custom,\n",
    "    'Random Forest': random_forest_custom,\n",
    "    'Boosting': boosting_custom\n",
    "}\n",
    "\n",
    "# Define evaluation metrics\n",
    "metrics = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': precision_score,\n",
    "    'Recall': recall_score,\n",
    "    'F1': f1_score,\n",
    "    'AUC': roc_auc_score\n",
    "}\n",
    "\n",
    "# Iterate through each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} on project_dataset2:\")\n",
    "    \n",
    "    # Initialize lists to store metric scores for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "\n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for train_index, test_index in skf.split(X2_scaled, y2):\n",
    "        X_train, X_test = X2_scaled[train_index], X2_scaled[test_index]\n",
    "        y_train, y_test = y2[train_index], y2[test_index] \n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate metrics\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "    # Display average scores over all folds for project_dataset1\n",
    "    print(f\"  Average Accuracy on project_dataset2: {np.mean(accuracy_scores):.4f}\")\n",
    "    print(f\"  Average Precision on project_dataset2: {np.mean(precision_scores):.4f}\")\n",
    "    print(f\"  Average Recall on project_dataset2: {np.mean(recall_scores):.4f}\")\n",
    "    print(f\"  Average F1 on project_dataset2: {np.mean(f1_scores):.4f}\")\n",
    "    print(f\"  Average AUC on project_dataset2: {np.mean(auc_scores):.4f}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
